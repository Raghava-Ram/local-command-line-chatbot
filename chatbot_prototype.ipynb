{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40d944a",
   "metadata": {},
   "source": [
    "# Local Chatbot Prototype\n",
    "\n",
    "This notebook demonstrates the functionality of our local chatbot using the HuggingFace Transformers library. We'll test various features including model loading, conversation handling, and response generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ced49a3",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Load Model\n",
    "\n",
    "First, let's import the necessary libraries and set up our model loader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546fdaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: distilgpt2...\n",
      "WARNING:tensorflow:From c:\\Users\\ragha\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to use CPU\n",
      "Model loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x1fb63868320>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_loader import ModelLoader\n",
    "from chat_memory import ChatMemory\n",
    "\n",
    "# Initialize the model and memory\n",
    "model = ModelLoader(model_name=\"distilgpt2\")\n",
    "memory = ChatMemory(max_turns=5)\n",
    "\n",
    "# Load the model\n",
    "model.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6845d639",
   "metadata": {},
   "source": [
    "## 2. Test Basic Conversation Flow\n",
    "\n",
    "Let's test the basic conversation flow with greetings and simple queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76471b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: hi\n",
      "Bot: Hi there! What can I assist you with?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test greeting\n",
    "user_input = \"hi\"\n",
    "memory.add_message(\"User\", user_input)\n",
    "response, query_type = model.generate_response(user_input, memory.buffer)\n",
    "print(f\"User: {user_input}\")\n",
    "print(f\"Bot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd76bd7f",
   "metadata": {},
   "source": [
    "## 3. Test Capital and Places Queries\n",
    "\n",
    "Now let's test the chatbot's ability to handle questions about capitals and places to visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0170a3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what is the capital of france\n",
      "Bot: The capital of France is Paris.\n",
      "\n",
      "User: what are some places to visit there\n",
      "Bot: France offers many famous attractions including the iconic Eiffel Tower, the Louvre Museum (home to the Mona Lisa), the Palace of Versailles, Mont Saint-Michel, and the beautiful French Riviera.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test capital query\n",
    "user_input = \"what is the capital of france\"\n",
    "memory.add_message(\"User\", user_input)\n",
    "response, query_type = model.generate_response(user_input, memory.buffer)\n",
    "print(f\"User: {user_input}\")\n",
    "print(f\"Bot: {response}\\n\")\n",
    "\n",
    "# Test follow-up query about places\n",
    "user_input = \"what are some places to visit there\"\n",
    "memory.add_message(\"User\", user_input)\n",
    "response, query_type = model.generate_response(user_input, memory.buffer)\n",
    "print(f\"User: {user_input}\")\n",
    "print(f\"Bot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b0600",
   "metadata": {},
   "source": [
    "## 4. Test Context Preservation\n",
    "\n",
    "Let's verify that the chatbot maintains context between questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d84693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what is the capital of italy\n",
      "Bot: The capital of Italy is Rome.\n",
      "\n",
      "User: what about germany\n",
      "Bot: .\n",
      "“I think it's a good idea to have the same kind of attitude, but I don't want that type and so we're going through this process in different ways,\" he said. \"We've got some great players who are\n",
      "\n",
      "User: tell me about places to visit there\n",
      "Bot: .”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test conversation with context\n",
    "queries = [\n",
    "    \"what is the capital of italy\",\n",
    "    \"what about germany\",\n",
    "    \"tell me about places to visit there\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    memory.add_message(\"User\", query)\n",
    "    response, query_type = model.generate_response(query, memory.buffer)\n",
    "    print(f\"User: {query}\")\n",
    "    print(f\"Bot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf7f66",
   "metadata": {},
   "source": [
    "## 5. Unit Tests\n",
    "\n",
    "Let's write some basic unit tests to verify the chatbot's functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b0912e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_capital_query (__main__.TestChatbot.test_capital_query) ... ok\n",
      "test_greeting (__main__.TestChatbot.test_greeting) ... ok\n",
      "test_places_query (__main__.TestChatbot.test_places_query) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1fb638682f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestChatbot(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.model = ModelLoader(\"distilgpt2\")\n",
    "        self.memory = ChatMemory(max_turns=5)\n",
    "        \n",
    "    def test_capital_query(self):\n",
    "        query = \"what is the capital of france\"\n",
    "        response, query_type = self.model.generate_response(query, [])\n",
    "        self.assertEqual(response, \"The capital of France is Paris.\")\n",
    "        self.assertEqual(query_type, \"capital\")\n",
    "        \n",
    "    def test_places_query(self):\n",
    "        query = \"places to visit in italy\"\n",
    "        response, query_type = self.model.generate_response(query, [])\n",
    "        self.assertTrue(\"Italy offers many famous attractions\" in response)\n",
    "        self.assertEqual(query_type, \"places\")\n",
    "        \n",
    "    def test_greeting(self):\n",
    "        query = \"hello\"\n",
    "        response, query_type = self.model.generate_response(query, [])\n",
    "        self.assertTrue(any(greeting in response for greeting in [\"Hi\", \"Hello\", \"Greetings\"]))\n",
    "        self.assertEqual(query_type, \"greeting\")\n",
    "\n",
    "# Run the tests\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
